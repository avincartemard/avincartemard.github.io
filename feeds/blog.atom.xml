<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>My Blog - Blog</title><link href="https://avincartemard.github.io/" rel="alternate"></link><link href="https://avincartemard.github.io/feeds/blog.atom.xml" rel="self"></link><id>https://avincartemard.github.io/</id><updated>2017-08-04T00:00:00+00:00</updated><entry><title>AI Fearmongering</title><link href="https://avincartemard.github.io/blog/2017/08/04/ai-fearmongering/" rel="alternate"></link><published>2017-08-04T00:00:00+00:00</published><updated>2017-08-04T00:00:00+00:00</updated><author><name>Alexandre Vincart-Emard</name></author><id>tag:avincartemard.github.io,2017-08-04:/blog/2017/08/04/ai-fearmongering/</id><summary type="html">&lt;p&gt;The future of AI is a topic of contention at the moment, with many prestigious names bringing their conflicting opinions to the table. On one hand there are the pessimists, supported by Elon Musk and Stephen Hawking, who warn about the potential threat AI poses to mankind's existence. On the other we find optimists like Mark Zuckerberg, who thinks that such fear mongering is not only &lt;a href="https://www.recode.net/2017/7/25/16026184/mark-zuckerberg-artificial-intelligence-elon-musk-ai-argument-twitter"&gt;negative but also irresponsible&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The idea that artificial intelligence could be dangerous is not new. A particularly widespread hypothesis of an AI doomsday scenario is that of the &lt;a href="https://en.wikipedia.org/wiki/Technological_singularity"&gt;singularity&lt;/a&gt;, the idea that an upgradable superintelligent agent could enter an ever-accelerating cycle of self-improvement until its problem-solving and inventive skills far surpass those of humanity. This agent could then proceed to build an even more intelligent machine and the cycle would repeat itself indefinitely, leaving no room for mankind in the process.&lt;/p&gt;
&lt;p&gt;We are obviously â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The future of AI is a topic of contention at the moment, with many prestigious names bringing their conflicting opinions to the table. On one hand there are the pessimists, supported by Elon Musk and Stephen Hawking, who warn about the potential threat AI poses to mankind's existence. On the other we find optimists like Mark Zuckerberg, who thinks that such fear mongering is not only &lt;a href="https://www.recode.net/2017/7/25/16026184/mark-zuckerberg-artificial-intelligence-elon-musk-ai-argument-twitter"&gt;negative but also irresponsible&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The idea that artificial intelligence could be dangerous is not new. A particularly widespread hypothesis of an AI doomsday scenario is that of the &lt;a href="https://en.wikipedia.org/wiki/Technological_singularity"&gt;singularity&lt;/a&gt;, the idea that an upgradable superintelligent agent could enter an ever-accelerating cycle of self-improvement until its problem-solving and inventive skills far surpass those of humanity. This agent could then proceed to build an even more intelligent machine and the cycle would repeat itself indefinitely, leaving no room for mankind in the process.&lt;/p&gt;
&lt;p&gt;We are obviously still very far away from such a catastrophic "intelligence explosion", but AI in its current form could still have disastrous consequences in the short-term if left unsupervised. Immediate concerns for policymakers are already numerous and pressing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Experts are still unsure about how the rise of AI will affect employment prospects in the near-future, especially for low- to middle-skilled jobs. Some argue that a universal basic income may be required in order to mitigate the societal upheaval caused by &lt;a href="https://futurism.com/heres-what-you-need-to-know-about-artificial-intelligence-and-universal-basic-income/"&gt;rapid technological unemployment&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine learning modeling carries the risk of encoding negative prejudices behind seemingly inoffensive proxies. For instance using postal code as a predictive feature can make an algorithm racist, whereas &lt;a href="http://www.wired.co.uk/article/machine-learning-bias-prejudice"&gt;flawed data collection practices can create a sexist bias&lt;/a&gt;. Such imperfect models are dangerous in that they provide a way for their users, who can be in a position of authority, to take unfair decisions while remaining unaccountable ("The algorithm said so.").&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The many benefits of Big Data come at the cost of our personal data being used for commercial ends. This raises growing concerns about the consequences of security breaches, the ethics of message targeting, and the &lt;a href="https://www.economist.com/news/technology-quarterly/21603233-it-security-increasing-commercial-use-personal-data-and-multiple"&gt;price of maintaining privacy&lt;/a&gt;, to name only a few. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During an &lt;a href="https://www.youtube.com/watch?v=2C-A797y8dA&amp;amp;feature=youtu.be&amp;amp;t=2900"&gt;interview at the National Governors Association&lt;/a&gt;, Musk insisted that "AI is a rare case where we need to be proactive about regulation instead of reactive. Because I think by the time we are reactive in AI regulation, it's too late." To his credit Musk's provocative and vivid warnings of an imminent AI doomsday are bound to ignite the population's imagination so that they pay attention to the increasingly important topic of artificial intelligence regulation. However it is fair to argue that we should first establish an appropriate regulatory framework to address foreseeable issues before worrying about existential threats beyond our imagination, else we would be working on very weak foundations. How can we properly regulate issues in a distant future we can barely imagine if we cannot agree on who is responsible when a self-driving car crashes?&lt;/p&gt;</content><category term="Artificial Intelligence"></category><category term="Technology"></category></entry><entry><title>Hello World</title><link href="https://avincartemard.github.io/blog/2017/07/24/hello-world/" rel="alternate"></link><published>2017-07-24T00:00:00+00:00</published><updated>2017-07-24T00:00:00+00:00</updated><author><name>Alexandre Vincart-Emard</name></author><id>tag:avincartemard.github.io,2017-07-24:/blog/2017/07/24/hello-world/</id><summary type="html">&lt;p&gt;After a week of fiddling and learning HTML and CSS on the fly, I finally managed to create a blog using &lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt;, a static site generator powered by Python that supports Markdown and reST syntax. &lt;/p&gt;
&lt;p&gt;Now that I have successfully defended my PhD thesis (which I verbosely titled "Numerical Investigation of Spatial Inhomogeneities in Gravity and Quantum Field Theory"), I have decided to take some time to blog about my progress as I transition towards a career in data science. This blog will be my platform to discuss all things related to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning;&lt;/li&gt;
&lt;li&gt;the ethics of Big Data;&lt;/li&gt;
&lt;li&gt;coding in Python;&lt;/li&gt;
&lt;li&gt;physics;&lt;/li&gt;
&lt;li&gt;interesting books I've read;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and more. Cheers!&lt;/p&gt;</summary><content type="html">&lt;p&gt;After a week of fiddling and learning HTML and CSS on the fly, I finally managed to create a blog using &lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt;, a static site generator powered by Python that supports Markdown and reST syntax. &lt;/p&gt;
&lt;p&gt;Now that I have successfully defended my PhD thesis (which I verbosely titled "Numerical Investigation of Spatial Inhomogeneities in Gravity and Quantum Field Theory"), I have decided to take some time to blog about my progress as I transition towards a career in data science. This blog will be my platform to discuss all things related to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning;&lt;/li&gt;
&lt;li&gt;the ethics of Big Data;&lt;/li&gt;
&lt;li&gt;coding in Python;&lt;/li&gt;
&lt;li&gt;physics;&lt;/li&gt;
&lt;li&gt;interesting books I've read;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and more. Cheers!&lt;/p&gt;</content><category term="Python"></category><category term="Pelican"></category></entry></feed>